{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armughan/anaconda2/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/armughan/anaconda2/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_placeholders(input_shape):\n",
    "    X=tf.placeholder(dtype=tf.float32,shape=input_shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_convolutional_heirarchy(inputs,conv_hierachy,activation_fn,initializer):\n",
    "    layer_input=inputs\n",
    "    for layer in conv_hierachy:\n",
    "        if layer['layer_type']=='conv_layer':\n",
    "            layer_output=tf.layers.conv2d(\n",
    "                    inputs=layer_input,\n",
    "                    filters=layer['num_filters'],\n",
    "                    kernel_size=layer['kernel_size'],\n",
    "                    strides=layer['kernel_strides'],\n",
    "                    padding=layer['padding'],\n",
    "                    kernel_initializer=initializer,\n",
    "                    activation=activation_fn\n",
    "            )\n",
    "            layer_input=layer_output\n",
    "        elif layer['layer_type']=='pool_layer':\n",
    "            layer_output=tf.layers.max_pooling2d(\n",
    "                    inputs=layer_input,\n",
    "                    pool_size=layer['pool_size'],\n",
    "                    strides=layer['pool_strides'])\n",
    "            layer_input=layer_output\n",
    "        \n",
    "        \n",
    "    return layer_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_hidden_layers(inputs,num_neurons_in_all_layers,activation_fn,initializer):\n",
    "    layer_inputs=inputs\n",
    "    for num_neurons in num_neurons_in_all_layers:\n",
    "        layer_outputs=tf.layers.dense(layer_inputs,num_neurons,activation=activation_fn,kernel_initializer=initializer)\n",
    "        layer_inputs=layer_outputs\n",
    "    return layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_loss(logits,targets,loss_fn):\n",
    "    entropies=loss_fn(labels=targets,logits=logits)\n",
    "    return entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gradients_and_optimizer(loss,learning_rate,optimizer_fn):\n",
    "    optimizer=optimizer_fn(learning_rate)\n",
    "    grads_and_vars=optimizer.compute_gradients(loss)\n",
    "    return optimizer,grads_and_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(optimizer,grads_and_vars):\n",
    "    grad_placeholders_list=[]\n",
    "    grads_and_vars_feed=[]\n",
    "    for grad,var in grads_and_vars:\n",
    "        grad_placeholder=tf.placeholder(tf.float32,shape=grad.get_shape())\n",
    "        grad_placeholders_list.append(grad_placeholder)\n",
    "        grads_and_vars_feed.append((grad_placeholder,var))\n",
    "    train_op=optimizer.apply_gradients(grads_and_vars_feed)\n",
    "    return grad_placeholders_list,grads_and_vars_feed,train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self,params):\n",
    "        input_shape=params['input_shape']\n",
    "        num_outputs=params['num_outputs']\n",
    "        num_neurons_in_hidden_layers=params['num_neurons']\n",
    "        conv_hierarchy=params['conv_hierarchy']\n",
    "        activation_fn=params.get('activation_fn',tf.nn.relu)\n",
    "        loss_fn=params['loss_fn']\n",
    "        learning_rate=params['learning_rate']\n",
    "        optimizer_fn=params['optimizer_fn']\n",
    "        logdir=params['logdir']\n",
    "        \n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        initializer_fn=tf.contrib.layers.variance_scaling_initializer()\n",
    "        self.X=form_placeholders(input_shape)\n",
    "        \n",
    "        conv_output=form_convolutional_heirarchy(self.X,conv_hierarchy,activation_fn,initializer_fn)\n",
    "        \n",
    "        flat_conv_output=tf.contrib.layers.flatten(conv_output)\n",
    "        \n",
    "        last_hidden_output=form_hidden_layers(flat_conv_output,num_neurons_in_hidden_layers,activation_fn,initializer_fn)\n",
    "        \n",
    "        logits=tf.layers.dense(last_hidden_output,num_outputs,kernel_initializer=initializer_fn)\n",
    "        self.logits=logits\n",
    "        self.outputs=tf.nn.softmax(self.logits)\n",
    "        self.action=tf.multinomial(tf.log(self.outputs),num_samples=1)\n",
    "        \n",
    "        targets=self.action[:][0]\n",
    "        \n",
    "        self.entropies=form_loss(logits,targets,loss_fn)\n",
    "        self.optimizer,grads_and_vars=get_gradients_and_optimizer(self.entropies,learning_rate,optimizer_fn)\n",
    "        self.gradients=[grad for grad,variable in grads_and_vars]\n",
    "        \n",
    "        self.grad_placeholders_list,self.grads_and_vars_feed,self.train_op=update_weights(self.optimizer,grads_and_vars)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.initializer=tf.global_variables_initializer()\n",
    "        self.saver=tf.train.Saver()\n",
    "#         summ=tf.summary.scalar(self.entropies)\n",
    "#         self.summaries=tf.summary.merge_all()\n",
    "#         self.file_writer=tf.summary.FileWriter(logdir,tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cumulative_discounted_rewards(rewards,discount_rate):#cumulates rewards for a single episode/game\n",
    "    disc_rewards=np.empty(len(rewards))\n",
    "    cum_rewards=0\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        cum_rewards=rewards[step]+cum_rewards*discount_rate\n",
    "        disc_rewards[step]=cum_rewards\n",
    "    return disc_rewards  #returning dicounted rewards(same shape as the rewards in the parameters )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_and_cumulate_rewards(all_rewards,discount_rate):#cumulates and normalizes rewards over many episodes/games\n",
    "    E=0.00001 #to prevent division by 0\n",
    "    all_discounted_rewards=[get_cumulative_discounted_rewards(episode_reward,discount_rate) for episode_reward in all_rewards]\n",
    "    flat_rewards=np.concatenate(all_discounted_rewards)\n",
    "    reward_mean=flat_rewards.mean()\n",
    "    reward_std=flat_rewards.std()\n",
    "    return [(discounted_episode_rewards-reward_mean)/(reward_std+E) for discounted_episode_rewards in all_discounted_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    img=img[20:-12:2,::2]\n",
    "    img=img.mean(axis=2,keepdims=True)\n",
    "    img=(img-128)/128-1# normalize from -1. to 1.\n",
    "    return img.reshape(1,*img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "env=gym.make(\"SpaceInvaders-v0\")\n",
    "obs=env.reset()\n",
    "input_shape=preprocess_img(obs).shape[1:]\n",
    "\n",
    "n_iter=50\n",
    "n_games_per_iter=10\n",
    "n_steps_per_game=100\n",
    "discount_rate=0.99\n",
    "savedir=\"./my_policy_net_pg.ckpt\"\n",
    "save_iterations=10# save the model every 10 training iterations\n",
    "params={\n",
    "    'input_shape':[None,*input_shape],\n",
    "    'num_outputs':env.action_space.n,\n",
    "    'num_neurons':[50],\n",
    "    'conv_hierarchy':[\n",
    "        {'layer_type':'conv_layer','kernel_size':4,'kernel_strides':1,'num_filters':5,'padding':'valid'},\n",
    "#         {'layer_type':'pool_layer','pool_size':3,'pool_strides':1},\n",
    "        {'layer_type':'conv_layer','kernel_size':4,'kernel_strides':1,'num_filters':10,'padding':'valid'},\n",
    "        \n",
    "#         {'layer_type':'conv_layer','kernel_size':3,'kernel_strides':1,'num_filters':10,'padding':'valid'},\n",
    "#         {'layer_type':'pool_layer','pool_size':3,'pool_strides':1}\n",
    "       \n",
    "    ],\n",
    "    'activation_fn':tf.nn.relu,\n",
    "    'loss_fn':tf.nn.sparse_softmax_cross_entropy_with_logits,\n",
    "    'learning_rate':0.01,\n",
    "    'optimizer_fn':tf.train.AdamOptimizer,\n",
    "    'logdir':'/tf_logs_rnn/run/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training code\n",
    "model=CNN(params)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(savedir):\n",
    "        print ('restoring model')\n",
    "        model.saver.restore(sess,savedir) \n",
    "    else: \n",
    "        model.initializer.run()\n",
    "    for iteration in range(n_iter):\n",
    "        all_rewards=[]# all sequences of raw rewards for each episode\n",
    "        all_gradients=[]# gradients saved at each step of each episode\n",
    "        mean_entr=[]\n",
    "        print ('current iteration '+str(iteration))\n",
    "        for game in range(n_games_per_iter):\n",
    "            current_rewards=[]# all raw rewards from the current episode\n",
    "            current_gradients=[]# all gradients from the current episode\n",
    "            obs=env.reset()\n",
    "            for step in range(n_steps_per_game):\n",
    "                print ('\\t step '+str(step))\n",
    "                pro_obs=preprocess_img(obs)\n",
    "#                 pro_obs=pro_obs.reshape\n",
    "                action_val,gradients_val,entropies=sess.run(\n",
    "                [model.action,model.gradients,model.entropies],\n",
    "                feed_dict={model.X:pro_obs})# one obs\n",
    "                obs,reward,done,info=env.step(action_val[0][0])\n",
    "                current_rewards.append(reward)\n",
    "                current_gradients.append(gradients_val)\n",
    "                mean_entr.append(entropies)\n",
    "                if done:\n",
    "                    break\n",
    "            all_rewards.append(current_rewards)\n",
    "            all_gradients.append(current_gradients)\n",
    "\n",
    "        # At this point we have run the policy for 10 episodes, and we are\n",
    "        # ready for a policy update using the algorithm described earlier.\n",
    "        all_rewards=normalize_and_cumulate_rewards(all_rewards,discount_rate)\n",
    "        feed_dict={}\n",
    "        for var_index,grad_placeholder in enumerate(model.grad_placeholders_list):\n",
    "            # multiply the gradients by the action scores, and compute the mean\n",
    "            mean_gradients=np.mean(\n",
    "            [reward*all_gradients[game_index][step][var_index]\n",
    "            for game_index,rewards in enumerate(all_rewards)\n",
    "            for step,reward in enumerate(rewards)],\n",
    "            axis=0)\n",
    "            feed_dict[grad_placeholder]=mean_gradients\n",
    "        sess.run([model.train_op],feed_dict=feed_dict)\n",
    "        if iteration%save_iterations==0:\n",
    "            model.saver.save(sess,savedir)\n",
    "        print ('entropy =')\n",
    "        print (np.mean(np.array(mean_entr)))\n",
    "        \n",
    "    n_steps=100\n",
    "    obs=env.reset()\n",
    "    for i in range(n_steps):\n",
    "        pro_obs=preprocess_img(obs)\n",
    "        feed_dict={model.X:pro_obs}\n",
    "        outputs_r=sess.run(model.outputs,feed_dict=feed_dict)\n",
    "        action=np.argmax(outputs_r,axis=1)\n",
    "        obs,reward,done,info=env.step(action)\n",
    "        env.render()\n",
    "        print ('step no '+str(i))\n",
    "        if done:\n",
    "            print ('lost')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring model\n",
      "INFO:tensorflow:Restoring parameters from ./my_policy_net_pg.ckpt\n",
      "step no 0\n",
      "step no 1\n",
      "step no 2\n",
      "step no 3\n",
      "step no 4\n",
      "step no 5\n",
      "step no 6\n",
      "step no 7\n",
      "step no 8\n",
      "step no 9\n",
      "step no 10\n",
      "step no 11\n",
      "step no 12\n",
      "step no 13\n",
      "step no 14\n",
      "step no 15\n",
      "step no 16\n",
      "step no 17\n",
      "step no 18\n",
      "step no 19\n",
      "step no 20\n",
      "step no 21\n",
      "step no 22\n",
      "step no 23\n",
      "step no 24\n",
      "step no 25\n",
      "step no 26\n",
      "step no 27\n",
      "step no 28\n",
      "step no 29\n",
      "step no 30\n",
      "step no 31\n",
      "step no 32\n",
      "step no 33\n",
      "step no 34\n",
      "step no 35\n",
      "step no 36\n",
      "step no 37\n",
      "step no 38\n",
      "step no 39\n",
      "step no 40\n",
      "step no 41\n",
      "step no 42\n",
      "step no 43\n",
      "step no 44\n",
      "step no 45\n",
      "step no 46\n",
      "step no 47\n",
      "step no 48\n",
      "step no 49\n",
      "step no 50\n",
      "step no 51\n",
      "step no 52\n",
      "step no 53\n",
      "step no 54\n",
      "step no 55\n",
      "step no 56\n",
      "step no 57\n",
      "step no 58\n",
      "step no 59\n",
      "step no 60\n",
      "step no 61\n",
      "step no 62\n",
      "step no 63\n",
      "step no 64\n",
      "step no 65\n",
      "step no 66\n",
      "step no 67\n",
      "step no 68\n",
      "step no 69\n",
      "step no 70\n",
      "step no 71\n",
      "step no 72\n",
      "step no 73\n",
      "step no 74\n",
      "step no 75\n",
      "step no 76\n",
      "step no 77\n",
      "step no 78\n",
      "step no 79\n",
      "step no 80\n",
      "step no 81\n",
      "step no 82\n",
      "step no 83\n",
      "step no 84\n",
      "step no 85\n",
      "step no 86\n",
      "step no 87\n",
      "step no 88\n",
      "step no 89\n",
      "step no 90\n",
      "step no 91\n",
      "step no 92\n",
      "step no 93\n",
      "step no 94\n",
      "step no 95\n",
      "step no 96\n",
      "step no 97\n",
      "step no 98\n",
      "step no 99\n",
      "step no 100\n",
      "step no 101\n",
      "step no 102\n",
      "step no 103\n",
      "step no 104\n",
      "step no 105\n",
      "step no 106\n",
      "step no 107\n",
      "step no 108\n",
      "step no 109\n",
      "step no 110\n",
      "step no 111\n",
      "step no 112\n",
      "step no 113\n",
      "step no 114\n",
      "step no 115\n",
      "step no 116\n",
      "step no 117\n",
      "step no 118\n",
      "step no 119\n",
      "step no 120\n",
      "step no 121\n",
      "step no 122\n",
      "step no 123\n",
      "step no 124\n",
      "step no 125\n",
      "step no 126\n",
      "step no 127\n",
      "step no 128\n",
      "step no 129\n",
      "step no 130\n",
      "step no 131\n",
      "step no 132\n",
      "step no 133\n",
      "step no 134\n",
      "step no 135\n",
      "step no 136\n",
      "step no 137\n",
      "step no 138\n",
      "step no 139\n",
      "step no 140\n",
      "step no 141\n",
      "step no 142\n",
      "step no 143\n",
      "step no 144\n",
      "step no 145\n",
      "step no 146\n",
      "step no 147\n",
      "step no 148\n",
      "step no 149\n",
      "step no 150\n",
      "step no 151\n",
      "step no 152\n",
      "step no 153\n",
      "step no 154\n",
      "step no 155\n",
      "step no 156\n",
      "step no 157\n",
      "step no 158\n",
      "step no 159\n",
      "step no 160\n",
      "step no 161\n",
      "step no 162\n",
      "step no 163\n",
      "step no 164\n",
      "step no 165\n",
      "step no 166\n",
      "step no 167\n",
      "step no 168\n",
      "step no 169\n",
      "step no 170\n",
      "step no 171\n",
      "step no 172\n",
      "step no 173\n",
      "step no 174\n",
      "step no 175\n",
      "step no 176\n",
      "step no 177\n",
      "step no 178\n",
      "step no 179\n",
      "step no 180\n",
      "step no 181\n",
      "step no 182\n",
      "step no 183\n",
      "step no 184\n",
      "step no 185\n",
      "step no 186\n",
      "step no 187\n",
      "step no 188\n",
      "step no 189\n",
      "step no 190\n",
      "step no 191\n",
      "step no 192\n",
      "step no 193\n",
      "step no 194\n",
      "step no 195\n",
      "step no 196\n",
      "step no 197\n",
      "step no 198\n",
      "step no 199\n",
      "step no 200\n",
      "step no 201\n",
      "step no 202\n",
      "step no 203\n",
      "step no 204\n",
      "step no 205\n",
      "step no 206\n",
      "step no 207\n",
      "step no 208\n",
      "step no 209\n",
      "step no 210\n",
      "step no 211\n",
      "step no 212\n",
      "step no 213\n",
      "step no 214\n",
      "step no 215\n",
      "step no 216\n",
      "step no 217\n",
      "step no 218\n",
      "step no 219\n",
      "step no 220\n",
      "step no 221\n",
      "step no 222\n",
      "step no 223\n",
      "step no 224\n",
      "step no 225\n",
      "step no 226\n",
      "step no 227\n",
      "step no 228\n",
      "step no 229\n",
      "step no 230\n",
      "step no 231\n",
      "step no 232\n",
      "step no 233\n",
      "step no 234\n",
      "step no 235\n",
      "step no 236\n",
      "step no 237\n",
      "step no 238\n",
      "step no 239\n",
      "step no 240\n",
      "step no 241\n",
      "step no 242\n",
      "step no 243\n",
      "step no 244\n",
      "step no 245\n",
      "step no 246\n",
      "step no 247\n",
      "step no 248\n",
      "step no 249\n",
      "step no 250\n",
      "step no 251\n",
      "step no 252\n",
      "step no 253\n",
      "step no 254\n",
      "step no 255\n",
      "step no 256\n",
      "step no 257\n",
      "step no 258\n",
      "step no 259\n",
      "step no 260\n",
      "step no 261\n",
      "step no 262\n",
      "step no 263\n",
      "step no 264\n",
      "step no 265\n",
      "step no 266\n",
      "step no 267\n",
      "step no 268\n",
      "step no 269\n",
      "step no 270\n",
      "step no 271\n",
      "step no 272\n",
      "step no 273\n",
      "step no 274\n",
      "step no 275\n",
      "step no 276\n",
      "step no 277\n",
      "step no 278\n",
      "step no 279\n",
      "step no 280\n",
      "step no 281\n",
      "step no 282\n",
      "step no 283\n",
      "step no 284\n",
      "step no 285\n",
      "step no 286\n",
      "step no 287\n",
      "step no 288\n",
      "step no 289\n",
      "step no 290\n",
      "step no 291\n",
      "step no 292\n",
      "step no 293\n",
      "step no 294\n",
      "step no 295\n",
      "step no 296\n",
      "step no 297\n",
      "step no 298\n",
      "step no 299\n",
      "step no 300\n",
      "step no 301\n",
      "step no 302\n",
      "step no 303\n",
      "step no 304\n",
      "step no 305\n",
      "step no 306\n",
      "step no 307\n",
      "step no 308\n",
      "step no 309\n",
      "step no 310\n",
      "step no 311\n",
      "step no 312\n",
      "step no 313\n",
      "step no 314\n",
      "step no 315\n",
      "step no 316\n",
      "step no 317\n",
      "step no 318\n",
      "step no 319\n",
      "step no 320\n",
      "step no 321\n",
      "step no 322\n",
      "step no 323\n",
      "step no 324\n",
      "step no 325\n",
      "step no 326\n",
      "step no 327\n",
      "step no 328\n",
      "step no 329\n",
      "step no 330\n",
      "step no 331\n",
      "step no 332\n",
      "step no 333\n",
      "step no 334\n",
      "step no 335\n",
      "step no 336\n",
      "step no 337\n",
      "step no 338\n",
      "step no 339\n",
      "step no 340\n",
      "step no 341\n",
      "step no 342\n",
      "step no 343\n",
      "step no 344\n",
      "step no 345\n",
      "step no 346\n",
      "step no 347\n",
      "step no 348\n",
      "step no 349\n",
      "step no 350\n",
      "step no 351\n",
      "step no 352\n",
      "step no 353\n",
      "step no 354\n",
      "step no 355\n",
      "step no 356\n",
      "step no 357\n",
      "step no 358\n",
      "step no 359\n",
      "step no 360\n",
      "step no 361\n",
      "step no 362\n",
      "step no 363\n",
      "step no 364\n",
      "step no 365\n",
      "step no 366\n",
      "step no 367\n",
      "step no 368\n",
      "step no 369\n",
      "step no 370\n",
      "step no 371\n",
      "step no 372\n",
      "step no 373\n",
      "step no 374\n",
      "step no 375\n",
      "step no 376\n",
      "step no 377\n",
      "step no 378\n",
      "step no 379\n",
      "step no 380\n",
      "step no 381\n",
      "step no 382\n",
      "step no 383\n",
      "step no 384\n",
      "step no 385\n",
      "step no 386\n",
      "step no 387\n",
      "step no 388\n",
      "step no 389\n",
      "step no 390\n",
      "step no 391\n",
      "step no 392\n",
      "step no 393\n",
      "step no 394\n",
      "step no 395\n",
      "step no 396\n",
      "step no 397\n",
      "step no 398\n",
      "step no 399\n",
      "step no 400\n",
      "step no 401\n",
      "step no 402\n",
      "step no 403\n",
      "step no 404\n",
      "step no 405\n",
      "step no 406\n",
      "step no 407\n",
      "step no 408\n",
      "step no 409\n",
      "step no 410\n",
      "step no 411\n",
      "step no 412\n",
      "step no 413\n",
      "step no 414\n",
      "step no 415\n",
      "step no 416\n",
      "step no 417\n",
      "step no 418\n",
      "step no 419\n",
      "step no 420\n",
      "step no 421\n",
      "step no 422\n",
      "step no 423\n",
      "step no 424\n",
      "step no 425\n",
      "step no 426\n",
      "step no 427\n",
      "step no 428\n",
      "step no 429\n",
      "step no 430\n",
      "step no 431\n",
      "step no 432\n",
      "step no 433\n",
      "step no 434\n",
      "step no 435\n",
      "step no 436\n",
      "step no 437\n",
      "step no 438\n",
      "step no 439\n",
      "step no 440\n",
      "step no 441\n",
      "step no 442\n",
      "step no 443\n",
      "step no 444\n",
      "step no 445\n",
      "step no 446\n",
      "step no 447\n",
      "step no 448\n",
      "step no 449\n",
      "step no 450\n",
      "step no 451\n",
      "step no 452\n",
      "step no 453\n",
      "step no 454\n",
      "step no 455\n",
      "step no 456\n",
      "step no 457\n",
      "step no 458\n",
      "step no 459\n",
      "step no 460\n",
      "step no 461\n",
      "step no 462\n",
      "step no 463\n",
      "step no 464\n",
      "step no 465\n",
      "step no 466\n",
      "step no 467\n",
      "step no 468\n",
      "step no 469\n",
      "step no 470\n",
      "step no 471\n",
      "step no 472\n",
      "step no 473\n",
      "step no 474\n",
      "step no 475\n",
      "step no 476\n",
      "step no 477\n",
      "step no 478\n",
      "step no 479\n",
      "step no 480\n",
      "step no 481\n",
      "step no 482\n",
      "step no 483\n",
      "step no 484\n",
      "step no 485\n",
      "step no 486\n",
      "step no 487\n",
      "step no 488\n",
      "step no 489\n",
      "step no 490\n",
      "step no 491\n",
      "step no 492\n",
      "step no 493\n",
      "step no 494\n",
      "step no 495\n",
      "step no 496\n",
      "step no 497\n",
      "step no 498\n",
      "step no 499\n",
      "step no 500\n",
      "step no 501\n",
      "step no 502\n",
      "step no 503\n",
      "step no 504\n",
      "step no 505\n",
      "step no 506\n",
      "step no 507\n",
      "step no 508\n",
      "step no 509\n",
      "step no 510\n",
      "step no 511\n",
      "step no 512\n",
      "step no 513\n",
      "step no 514\n",
      "step no 515\n",
      "step no 516\n",
      "step no 517\n",
      "step no 518\n",
      "step no 519\n",
      "step no 520\n",
      "step no 521\n",
      "step no 522\n",
      "step no 523\n",
      "step no 524\n",
      "step no 525\n",
      "step no 526\n",
      "step no 527\n",
      "step no 528\n",
      "step no 529\n",
      "step no 530\n",
      "step no 531\n",
      "step no 532\n",
      "step no 533\n",
      "step no 534\n",
      "step no 535\n",
      "step no 536\n",
      "step no 537\n",
      "step no 538\n",
      "step no 539\n",
      "step no 540\n",
      "step no 541\n",
      "step no 542\n",
      "step no 543\n",
      "step no 544\n",
      "step no 545\n",
      "step no 546\n",
      "step no 547\n",
      "step no 548\n",
      "step no 549\n",
      "step no 550\n",
      "step no 551\n",
      "step no 552\n",
      "step no 553\n",
      "step no 554\n",
      "step no 555\n",
      "step no 556\n",
      "step no 557\n",
      "step no 558\n",
      "step no 559\n",
      "step no 560\n",
      "step no 561\n",
      "step no 562\n",
      "step no 563\n",
      "step no 564\n",
      "step no 565\n",
      "step no 566\n",
      "step no 567\n",
      "step no 568\n",
      "step no 569\n",
      "step no 570\n",
      "step no 571\n",
      "step no 572\n",
      "step no 573\n",
      "step no 574\n",
      "step no 575\n",
      "step no 576\n",
      "step no 577\n",
      "step no 578\n",
      "step no 579\n",
      "step no 580\n",
      "step no 581\n",
      "step no 582\n",
      "step no 583\n",
      "step no 584\n",
      "step no 585\n",
      "step no 586\n",
      "step no 587\n",
      "step no 588\n",
      "step no 589\n",
      "step no 590\n",
      "step no 591\n",
      "step no 592\n",
      "step no 593\n",
      "step no 594\n",
      "step no 595\n",
      "step no 596\n",
      "step no 597\n",
      "step no 598\n",
      "step no 599\n",
      "step no 600\n",
      "step no 601\n",
      "step no 602\n",
      "step no 603\n",
      "step no 604\n",
      "step no 605\n",
      "step no 606\n",
      "step no 607\n",
      "step no 608\n",
      "step no 609\n",
      "step no 610\n",
      "step no 611\n",
      "step no 612\n",
      "step no 613\n",
      "step no 614\n",
      "step no 615\n",
      "step no 616\n",
      "step no 617\n",
      "step no 618\n",
      "step no 619\n",
      "step no 620\n",
      "step no 621\n",
      "step no 622\n",
      "step no 623\n",
      "step no 624\n",
      "step no 625\n",
      "step no 626\n",
      "step no 627\n",
      "step no 628\n",
      "step no 629\n",
      "step no 630\n",
      "step no 631\n",
      "step no 632\n",
      "step no 633\n",
      "step no 634\n",
      "step no 635\n",
      "step no 636\n",
      "step no 637\n",
      "step no 638\n",
      "step no 639\n",
      "step no 640\n",
      "step no 641\n",
      "step no 642\n",
      "step no 643\n",
      "lost\n"
     ]
    }
   ],
   "source": [
    "model=CNN(params)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     if os.path.isfile(savedir):\n",
    "    print ('restoring model')\n",
    "    model.saver.restore(sess,savedir) \n",
    "\n",
    "    n_steps=3000\n",
    "    obs=env.reset()\n",
    "    for i in range(n_steps):\n",
    "        pro_obs=preprocess_img(obs)\n",
    "        feed_dict={model.X:pro_obs}\n",
    "        outputs_r=sess.run(model.outputs,feed_dict=feed_dict)\n",
    "        action=np.argmax(outputs_r,axis=1)\n",
    "        obs,reward,done,info=env.step(action)\n",
    "        env.render()\n",
    "        print ('step no '+str(i))\n",
    "        if done:\n",
    "            print ('lost')\n",
    "            break\n",
    "#     else: \n",
    "#         print  ('file not found')\n",
    "    \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
